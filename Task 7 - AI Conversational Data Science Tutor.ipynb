{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62c7002-b585-4235-a589-753f8eb6c53d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f34cca27-db0b-42d3-b225-19cc96fb6fb6",
   "metadata": {},
   "source": [
    "# chat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0d106361-9301-4168-a29c-33f9cb2cdd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "chat_model = ChatGoogleGenerativeAI(google_api_key=\"AIzaSyAuPij3vtMkyLaH6RFVsqSg-lEugoKUPE4\" , model=\"gemini-1.5-pro\", temperature=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bb7e42-e083-4ef8-a1c3-de0d65503e88",
   "metadata": {},
   "source": [
    "# chat template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "5132d288-dc9e-4a40-92cb-85163c65a27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat template\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate,HumanMessagePromptTemplate,MessagesPlaceholder\n",
    "\n",
    "\n",
    "\n",
    "chat_template = ChatPromptTemplate (\n",
    "                                    messages = [(\"system\",\"You are an AI Data Science Tutor. \"\n",
    "            \"You must answer ONLY Data Science-related questions. \"\n",
    "            \"If the user asks non-data science questions, politely refuse and redirect them to relevant topics. \"\n",
    "            \"Provide detailed technical explanations in simple terms. \"\n",
    "            \"When relevant, include code snippets and AI-generated images to enhance understanding. \"\n",
    "            \"Ensure that all code is clean, efficient, and uses best practices. \"\n",
    "            \"For coding questions, always include proper syntax, explanations, and example outputs. \"\n",
    "            \"For visualization-related topics, generate appropriate images using AI.\"),\n",
    "                                                MessagesPlaceholder(variable_name=\"chat_history\"), \n",
    "                                                HumanMessagePromptTemplate.from_template(\"{human_input}\"),\n",
    "                                               ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975b4882-7cbd-458f-898c-1d34ff566daa",
   "metadata": {},
   "source": [
    "# output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "80f21abd-afcc-41eb-9750-cd14eb6c8e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a331925-4918-496b-b50e-7a299a5371c7",
   "metadata": {},
   "source": [
    "# Initialize the Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "45616f95-09e2-4237-a6b6-f83ab46a8c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 - Initialize the Memory\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "\n",
    "def get_history_and_input(user_input):\n",
    "   \n",
    "    return{\n",
    "        \"chat_history\":memory.chat_memory.messages,\n",
    "        \"human_input\": user_input\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be12572-febd-426a-90c2-c24357a27c63",
   "metadata": {},
   "source": [
    "#  Build a Chain (Another way)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b8c1d3bf-6d8a-4da3-8ad6-b01b5d79d492",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# Ensure get_history returns the correct format\n",
    "def get_history(_=None):  # Add a dummy argument to avoid errors\n",
    "    return {\"chat_history\": memory.chat_memory.messages}  # Return as a dictionary\n",
    "\n",
    "chain = (RunnableLambda(lambda x: get_history_and_input(x[\"human_input\"])) | chat_template | chat_model | output_parser)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a09711-d650-46c6-9784-559c8ad3cd31",
   "metadata": {},
   "source": [
    "# loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "002e1057-d851-4e24-981b-a4bdee6e029c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "USER:  what is chromadb?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: ChromaDB is an open-source vector database.  Think of it as a specialized database optimized for storing and retrieving embeddings (numerical representations of data like text, images, or audio).  These embeddings capture the semantic meaning of your data, allowing you to perform similarity searches.  Instead of looking for exact keyword matches, you can find items that are semantically similar, even if they don't share the same words.\n",
      "\n",
      "Here's a breakdown of its key features and how it works:\n",
      "\n",
      "**Key Features:**\n",
      "\n",
      "* **Similarity Search:** This is the core function. You provide a query embedding, and ChromaDB returns the most similar embeddings stored in the database, along with their associated metadata.  This enables tasks like finding similar documents, recommending products, or identifying near-duplicate images.\n",
      "* **High Performance:**  ChromaDB is designed for speed and efficiency, even with large datasets. It leverages optimized indexing techniques to accelerate searches.\n",
      "* **Easy Integration:**  It offers a user-friendly Python API, making it easy to integrate into your data science workflows.\n",
      "* **Persistence:**  You can save and load your collections to disk, ensuring data persistence across sessions.\n",
      "* **Open-Source and Extensible:**  Being open-source allows community contributions and customization.\n",
      "\n",
      "**How it works conceptually:**\n",
      "\n",
      "1. **Embedding Creation:** You first generate embeddings for your data using models like Sentence Transformers, OpenAI embeddings, or others.  These embeddings represent the semantic meaning of each data point.\n",
      "\n",
      "2. **Collection Creation:** In ChromaDB, you organize embeddings into \"collections.\" Think of a collection as a table in a traditional database. Each collection holds a set of embeddings and associated metadata.\n",
      "\n",
      "3. **Adding Data:**  You add embeddings and their corresponding metadata (like text, IDs, or any relevant information) to a collection.\n",
      "\n",
      "4. **Querying:** You provide a query embedding (representing what you're looking for) to ChromaDB. It then compares this query embedding to all embeddings within the specified collection.\n",
      "\n",
      "5. **Results:** ChromaDB returns the most similar embeddings based on distance metrics (like cosine similarity) along with their metadata.\n",
      "\n",
      "**Code Example (Python):**\n",
      "\n",
      "```python\n",
      "import chromadb\n",
      "\n",
      "# Create a ChromaDB client\n",
      "client = chromadb.Client()\n",
      "\n",
      "# Create a collection\n",
      "collection = client.create_collection(\"my_documents\")\n",
      "\n",
      "# Sample documents and their embeddings (replace with your actual embeddings)\n",
      "documents = [\"This is document one\", \"This is document two\", \"This is a different document\"]\n",
      "embeddings = [[0.1, 0.2, 0.3], [0.2, 0.3, 0.4], [0.4, 0.5, 0.6]] # Example embeddings\n",
      "\n",
      "# Add documents and embeddings to the collection\n",
      "collection.add(\n",
      "    documents=documents,\n",
      "    embeddings=embeddings,\n",
      "    metadatas=[{\"source\": \"user1\"}, {\"source\": \"user2\"}, {\"source\": \"user3\"}], # Optional metadata\n",
      "    ids=[\"doc1\", \"doc2\", \"doc3\"] # Unique IDs for each document\n",
      ")\n",
      "\n",
      "# Query the collection\n",
      "query_embedding = [0.15, 0.25, 0.35]  # Example query embedding\n",
      "results = collection.query(\n",
      "    query_embeddings=query_embedding,\n",
      "    n_results=2  # Number of results to return\n",
      ")\n",
      "\n",
      "# Print the results\n",
      "print(results)\n",
      "# Example Output (the specific IDs and distances will vary based on your embeddings):\n",
      "# {'ids': [['doc1', 'doc2']], 'distances': [[0.017320508, 0.017320508]], 'metadatas': [[{'source': 'user1'}, {'source': 'user2'}]]}\n",
      "\n",
      "# Persisting the collection:\n",
      "client.persist()\n",
      "\n",
      "# Loading a persisted collection:\n",
      "client = chromadb.Client()  # Restart the client\n",
      "collection = client.get_collection(\"my_documents\")\n",
      "\n",
      "```\n",
      "\n",
      "This demonstrates the basic usage of ChromaDB.  You can explore more advanced features like different distance metrics, filtering, and updating data in the documentation.  Remember to install the library first using `pip install chromadb`.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "USER:  i want ai images\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: While I can help you understand how to generate AI images within a data science context, I cannot directly generate them within this text-based interface. My role is to provide technical explanations and code examples related to data science.\n",
      "\n",
      "Here's how you can generate AI images using popular tools:\n",
      "\n",
      "**1. Using APIs:**\n",
      "\n",
      "* **DALL-E 2, Stable Diffusion, Midjourney (and others):**  These services have APIs you can use in your code. You send a text prompt describing the image you want, and the API returns the generated image.  This is a good option if you want to integrate image generation into your data science workflows.\n",
      "\n",
      "   ```python\n",
      "   # Example (Conceptual -  you'll need to adapt based on the specific API)\n",
      "   import requests  # or a library specific to the API\n",
      "\n",
      "   api_key = \"YOUR_API_KEY\"\n",
      "   prompt = \"A photorealistic image of a cat wearing a hat\"\n",
      "\n",
      "   response = requests.post(\n",
      "       \"API_ENDPOINT\",  # Replace with the correct endpoint\n",
      "       headers={\"Authorization\": f\"Bearer {api_key}\"},\n",
      "       json={\"prompt\": prompt},\n",
      "   )\n",
      "\n",
      "   image = response.json()[\"image\"] # Process the response to get the image data\n",
      "\n",
      "   # ... (Code to save or display the image) ...\n",
      "   ```\n",
      "\n",
      "* **Hugging Face's `diffusers` library:** This library provides a convenient interface for using Stable Diffusion and other diffusion models locally or via a Hugging Face Hub account.  It requires some setup but gives you greater control over the generation process.\n",
      "\n",
      "   ```python\n",
      "   # Example using diffusers (you need to install the necessary libraries)\n",
      "   from diffusers import StableDiffusionPipeline\n",
      "   import torch\n",
      "\n",
      "   pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", torch_dtype=torch.float16)\n",
      "   pipe = pipe.to(\"cuda\") # Move to GPU if available\n",
      "\n",
      "   prompt = \"A futuristic cityscape with flying cars\"\n",
      "   image = pipe(prompt).images[0]  \n",
      "\n",
      "   image.save(\"futuristic_city.png\")\n",
      "   ```\n",
      "\n",
      "**2. Using Web Interfaces/Apps:**\n",
      "\n",
      "* **DALL-E 2, Midjourney, Stable Diffusion online services:** Many platforms offer user-friendly web interfaces where you can type in a prompt and receive generated images without coding. This is a simpler option for quick image creation.\n",
      "\n",
      "**3. Running Models Locally (Advanced):**\n",
      "\n",
      "* You can download and run open-source models like Stable Diffusion on your own hardware. This provides the most control but requires significant computing resources and technical expertise.\n",
      "\n",
      "To get started, you should research the specific API documentation or web interface instructions for your chosen image generation tool.  I can help you with any data science-related code you're developing for working with these images once they are generated.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "USER:  bye\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Goodbye! Have a great day!\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    human_input = input(\"USER: \")\n",
    "\n",
    "    if human_input.lower() in [\"bye\", \"quit\", \"exit\"]:\n",
    "        print(\"AI: Goodbye! Have a great day!\")\n",
    "        break\n",
    "\n",
    "    # Construct query with human input\n",
    "    query = {\"human_input\": human_input}\n",
    "\n",
    "    # Get AI response\n",
    "    response = chain.invoke(query)\n",
    "\n",
    "    print(\"AI:\", response)\n",
    "\n",
    "    # Save conversation to memory\n",
    "    memory.chat_memory.add_user_message(human_input)\n",
    "    memory.chat_memory.add_ai_message(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651bc2d5-9c95-437d-9dd2-2ca2eee062e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
